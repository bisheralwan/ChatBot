{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bisheralwan/ChatBot/blob/main/W2025/Assignments/A3/SYSC4415_W25_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcaEf9LdAu9k"
      },
      "source": [
        "# Welcome to Assignment 3\n",
        "\n",
        "**TA: [Igor Bogdanov](mailto:igorbogdanov@cmail.carleton.ca)**\n",
        "\n",
        "## General Instructions:\n",
        "\n",
        "This Assignment can be done **in a group of two or individually**.\n",
        "\n",
        "YOU HAVE TO JOIN A GROUP ON BRIGHTSPACE TO SUBMIT.\n",
        "\n",
        "Please state it explicitly at the beginning of the assignment.\n",
        "\n",
        "You need only one submission if it's group work.\n",
        "\n",
        "Please print out values when asked using Python's print() function with f-strings where possible.\n",
        "\n",
        "Submit your **saved notebook with all the outputs** to Brightspace, but ensure it will produce correct outputs upon restarting and click \"runtime\" → \"run all\" with clean outputs. Ensure your notebook displays all answers correctly.\n",
        "\n",
        "## Your Submission MUST contain your signature at the bottom.\n",
        "\n",
        "### Objective:\n",
        "In this assignment, we build a reasoning AI agent that facilitates ML operations and model evaluation. This assignment is heavily based on Tutorial 9.\n",
        "\n",
        "**Submission:** Submit your Notebook as a *.ipynb* file that adopts this naming convention: ***SYSC4415_W25_A3_NameLastname.ipynb*** on *Brightspace*. No other submission (e.g., through email) will be accepted. (Example file name: SYSC4415_W25_A3_IgorBogdanov.ipynb or SYSC4415_W25_A3_Student1_Student2.ipynb) The notebool MUST contain saved outputs\n",
        "\n",
        "**Runtime tips:**\n",
        "Agentic programming and API calling can be easily done locally and moved to Colab in the final stages, depending on the implementation of your tools and ML tasks you want to run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIzWURYdCos_"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyRG5AEHNILq"
      },
      "source": [
        "Some basic libraries you need are imported here. Make sure you include whatever library you need in this entire notebook in the code block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXYKklNMNpbQ"
      },
      "source": [
        "If you are using any library that requires installation, please paste the installation command here.\n",
        "Leave the code block below if you are not installing any libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NZEeRARqqPp8"
      },
      "outputs": [],
      "source": [
        "# Name: Bisher Abou-Alwan\n",
        "# Student Number: 101211242\n",
        "\n",
        "# Name: Mohammad Abusalem\n",
        "# Student Number: 101204665"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CrxZ_P9tNkln"
      },
      "outputs": [],
      "source": [
        "# Libraries to install - leave this code block blank if this does not apply to you\n",
        "# Please add a brief comment on why you need the library and what it does\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3_N_y3sNfTC",
        "outputId": "f5749b10-a0e9-47bf-8d69-8fe8528bfb9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install groq\n",
        "\n",
        "# Libraries you might need\n",
        "# General\n",
        "import os\n",
        "import zipfile\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# For pre-processing\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# For modeling\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchsummary\n",
        "\n",
        "# For metrics\n",
        "from sklearn.metrics import  accuracy_score\n",
        "from sklearn.metrics import  precision_score\n",
        "from sklearn.metrics import  recall_score\n",
        "from sklearn.metrics import  f1_score\n",
        "from sklearn.metrics import  classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import  roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Agent\n",
        "from groq import Groq\n",
        "from dataclasses import dataclass\n",
        "import re\n",
        "from typing import Dict, List, Optional\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vX4Z_nNI6BY"
      },
      "source": [
        "# Task 1: Registration and API Activation (5 marks)\n",
        "\n",
        "For this particular assignment, we will be using GroqCloud for LLM inference. This task aims to determine how to use the Groq API with LLMs.  \n",
        "\n",
        "Create a free account on https://groq.com/ and generate an API Key. Don't remove your key until you get your grade. Feel free to delete your API key after the term is completed.\n",
        "\n",
        "In conversational AI, prompting involves three key roles: the system role (which sets the agent's behavior and capabilities), the user role (which represents human inputs and queries), and the assistant role (which contains the agent's responses). The system role provides the foundational instructions and constraints, the user role delivers the actual queries or commands, and the assistant role generates contextual, step-by-step responses following the system's guidelines. This structured approach ensures consistent, controlled interactions where the agent maintains its defined behavior while responding to user needs, with each role serving a specific purpose in the conversation flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5tSc4kOsghn_"
      },
      "outputs": [],
      "source": [
        "# Q1a (2 mark)\n",
        "# Create a client using your API key.\n",
        "\n",
        "client = Groq(api_key=\"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\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KT-vxP0QI74n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccab05a2-d930-432a-d35c-7b055f87a36a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Penguins are indeed birds, but they have evolved to become flightless over time. There are several reasons for this:\n",
            "\n",
            "1. **Environmental pressures**: Penguins live in the Southern Hemisphere, where the climate is cold and the oceans are rich in food. As a result, they didn't need to fly to find food or escape predators. In fact, flying would have been energetically expensive and potentially hazardous in the strong winds and icy conditions.\n",
            "2. **Body shape and size**: Penguins have a unique body shape, with a streamlined torso, flippers, and a heavy skeleton. This shape is ideal for swimming and diving, but not for flying. Their wings are modified to be more suited for propulsion through water than through air.\n",
            "3. **Wing structure**: Penguins' wings are shorter and more rigid than those of flying birds. They have a solid, flipper-like shape that allows them to use their wings to \"fly\" through the water, but they lack the flexibility and lift needed to generate lift in the air.\n",
            "4. **Energy efficiency**: Flying is an energetically expensive activity, requiring a lot of energy to generate lift and stay aloft. Penguins have evolved to conserve energy by using their powerful flippers to swim and dive, which is more efficient for them than flying.\n",
            "5. **Evolutionary trade-offs**: As penguins adapted to their aquatic environment, they likely made trade-offs in terms of energy allocation. They invested energy in developing strong swimming muscles, a streamlined body, and a thick layer of fat to keep warm, rather than maintaining the ability to fly.\n",
            "\n",
            "Over time, these factors led to the evolution of penguins as flightless birds, with their unique adaptations allowing them to thrive in their aquatic environment. While they may not fly through the air, penguins are incredibly agile and efficient swimmers, able to reach speeds of up to 25 miles per hour (40 kilometers per hour) in the water.\n"
          ]
        }
      ],
      "source": [
        "# Q1b (3 marks)\n",
        "\n",
        "# instantiate chat_completion object using model of your choice (llama-3.3-70b-versatile - recommended)\n",
        "# Hint: Use Tutorial 9 and Groq Documentation\n",
        "# Explain each parameter and how each value change influences the LLM's output.\n",
        "# Prompt the model using the user role about anything different from the tutorial.\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that provides facts and reasoning.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Why do penguins not fly even though they are birds?\"}\n",
        "    ],\n",
        "    temperature=0.2,\n",
        "    top_p=0.7,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "# Print the assistant’s response\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2f2stNqCmP_"
      },
      "source": [
        "# Task 2: Agent Implementation (5 marks)\n",
        "\n",
        "This task contains an implementation of the agent from Tutorial 9. The idea of this task is to make sure you understand how basic LLM-Agent works.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "feUcU4mCl2rn"
      },
      "outputs": [],
      "source": [
        "# Q2a: (5 marks) Explain how agent implementation works, providing comments line by line.\n",
        "# This paper might be helpful: https://react-lm.github.io/\n",
        "\n",
        "#This data class keeps track of what the agent has said and been told\n",
        "@dataclass\n",
        "class Agent_State:\n",
        "    messages: List[Dict[str, str]] #stores conversation messages between user and agent\n",
        "    system_prompt: str #sets the overall behavior and tone of the agent\n",
        "\n",
        "#The ML_Agent class is the core of our reasoning agent\n",
        "class ML_Agent:\n",
        "    def __init__(self, system_prompt: str):\n",
        "        #This sets up the client that talks to the LLM\n",
        "        self.client = client\n",
        "\n",
        "        #The agent’s memory starts with just the system prompt\n",
        "        self.state = Agent_State(\n",
        "            messages=[{\"role\": \"system\", \"content\": system_prompt}],\n",
        "            system_prompt=system_prompt,\n",
        "        )\n",
        "\n",
        "    def add_message(self, role: str, content: str) -> None:\n",
        "        #Add a new message to the conversation (user or assistant)\n",
        "        self.state.messages.append({\"role\": role, \"content\": content})\n",
        "\n",
        "    def execute(self) -> str:\n",
        "        #This sends all past messages to the LLM and gets the latest reply\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\", #the chosen LLM model\n",
        "            temperature=0.2, #low randomness (more predictable)\n",
        "            top_p=0.7, #controls how many token options are considered\n",
        "            max_tokens=1024, #maximum length of the response\n",
        "            messages=self.state.messages, #full conversation history\n",
        "        )\n",
        "        return completion.choices[0].message.content #return just the reply text\n",
        "\n",
        "    def __call__(self, message: str) -> str:\n",
        "        self.add_message(\"user\", message) #add the user's input\n",
        "        result = self.execute() #get the agent's response\n",
        "        self.add_message(\"assistant\", result) #save the agent's reply\n",
        "        return result #return the final answer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3eOrZAElyrH"
      },
      "source": [
        "# Task 3: Tools (20 marks)\n",
        "\n",
        "Tools are specialized functions that enable AI agents to perform specific actions beyond their inherent capabilities, such as retrieving information, performing calculations, or manipulating data. Agents use tools to decompose complex reasoning into observable steps, extend their knowledge beyond training data, maintain state across interactions, and provide transparency in their decision-making process, ultimately allowing them to solve problems they couldn't tackle through reasoning alone.\n",
        "\n",
        "Essentially, tools are just callback functions invoked by the agent at the appropriate time during the execution loop.\n",
        "\n",
        "You need to plan your tools for each particular task your agent is expected to solve.\n",
        "The Model Evaluation Agent we are building should be able to evaluate the model from the model pool on the specific dataset.\n",
        "\n",
        "Datasets to use: Penguins, Iris, CIFAR-10\n",
        "\n",
        "You should be able to tell the agent what to do and watch it display the output of the tools' execution, similar to that in Tutorial 9.\n",
        "\n",
        "User Prompt examples you should be able to give to your agent and expect it to fulfill the task:\n",
        "- **Evaluate Linear Regression Model on Iris Dataset**\n",
        "- **Train a logistic regression model on the Iris dataset**\n",
        "- **Load the Penguins dataset and preprocess it.**\n",
        "- **Train a decision tree model on the Penguins dataset and evaluate it.**\n",
        "- **Load the CIFAR-10 dataset and train Mini-ResNet CNN, visualize results**\n",
        "\n",
        "Classifier Models for Iris and Penguins (use A1 and early tutorials):\n",
        "  * Logistic Regression (solver='lbfgs')\n",
        "  * Decision Tree (max_depth=3)\n",
        "  * KNN (n_neighbors=5)\n",
        "\n",
        "Any 2 CNN models of your choice for CIFAR-10 dataset (do some research, don't create anything from scratch unless you want to, use the ones provided by libraries and frameworks)\n",
        "\n",
        "HINT: It is highly recommended that any code from previous assignments and tutorials be reused for tool implementation.\n",
        "\n",
        "**Use Pytorch where possible**\n",
        "\n",
        "## DON'T FORGET TO IMPORT MISSING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PnqADgZqqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3a (3 marks): Implement model_memory tool.\n",
        "# This tool should provide the agent with details about models or datasets\n",
        "# Example: when asked about Penguin dataset, the agent can use memory to look up\n",
        "# the source to obtain the dataset.\n",
        "\n",
        "\n",
        "def model_memory(query: str) -> str:\n",
        "    query = query.lower().strip()\n",
        "\n",
        "    #Predefined knowledge base\n",
        "    memory = {\n",
        "        \"iris dataset\": \"The Iris dataset contains 3 classes of 50 instances each, with 4 features (sepal/petal length/width).\",\n",
        "        \"penguins dataset\": \"The Penguins dataset includes 3 species of penguins with features like flipper length and body mass.\",\n",
        "        \"cifar-10 dataset\": \"CIFAR-10 contains 60,000 32x32 color images across 10 categories like airplane, dog, and truck.\",\n",
        "        \"logistic regression\": \"A linear classifier that uses the logistic function to model probabilities.\",\n",
        "        \"decision tree\": \"A tree-based model that splits data based on feature thresholds. Easy to interpret. Use max_depth=3 for simplicity.\",\n",
        "        \"knn\": \"K-Nearest Neighbors (KNN) classifies a sample based on the majority label of its k closest points. Use n_neighbors=5.\",\n",
        "        \"cnn\": \"Convolutional Neural Networks (CNNs) are deep learning models designed for visual recognition tasks like image classification.\"\n",
        "    }\n",
        "\n",
        "    return memory.get(query, f\"No known entry for '{query}'. Try asking about a dataset or model.\") #now return match or fallback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8sPHHfdVqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3b (3 marks): Implement dataset_loader tool.\n",
        "# loads dataset after obtaining info from memory\n",
        "\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "import seaborn as sns\n",
        "\n",
        "def dataset_loader(dataset_name: str):\n",
        "    dataset_name = dataset_name.lower().strip()\n",
        "\n",
        "    if dataset_name == \"iris\":\n",
        "        data = load_iris(as_frame=True)\n",
        "        df = data.frame\n",
        "        return df.head().to_string() #preview only\n",
        "\n",
        "    elif dataset_name == \"penguins\":\n",
        "        df = sns.load_dataset(\"penguins\")\n",
        "        return df.head().to_string() #preview only\n",
        "\n",
        "    elif dataset_name == \"cifar-10\":\n",
        "        return \"CIFAR-10 will be loaded using torchvision.datasets when training starts (due to its size).\"\n",
        "\n",
        "    else:\n",
        "        return f\"Dataset '{dataset_name}' not recognized. Please choose Iris, Penguins, or CIFAR-10.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WNpzf3LSqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3c (3 marks): Implement dataset_preprocessing tool.\n",
        "# preprocesses the dataset to work with the chosen model, and does the splits\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#Global state so other tools (like training) can use the preprocessed data\n",
        "PREPROCESSED_DATA = {}\n",
        "\n",
        "def dataset_preprocessing(dataset_name: str) -> str:\n",
        "    dataset_name = dataset_name.lower().strip()\n",
        "\n",
        "    if dataset_name == \"iris\":\n",
        "        from sklearn.datasets import load_iris\n",
        "        data = load_iris(as_frame=True)\n",
        "        df = data.frame\n",
        "        X = df.drop(columns=[\"target\"])\n",
        "        y = df[\"target\"]\n",
        "\n",
        "    elif dataset_name == \"penguins\":\n",
        "        import seaborn as sns\n",
        "        df = sns.load_dataset(\"penguins\").dropna()\n",
        "        df = df.select_dtypes(include=[float, int])  # remove non-numerical columns like species\n",
        "        X = df.drop(columns=[\"body_mass_g\"]) if \"body_mass_g\" in df else df.iloc[:, :-1]\n",
        "        y = df[\"body_mass_g\"] if \"body_mass_g\" in df else df.iloc[:, -1]\n",
        "\n",
        "    else:\n",
        "        return f\"Preprocessing not supported for dataset '{dataset_name}'. Try 'iris' or 'penguins'.\"\n",
        "\n",
        "    #Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    #Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    #Save for other tools to use\n",
        "    PREPROCESSED_DATA[\"X_train\"] = X_train\n",
        "    PREPROCESSED_DATA[\"X_test\"] = X_test\n",
        "    PREPROCESSED_DATA[\"y_train\"] = y_train\n",
        "    PREPROCESSED_DATA[\"y_test\"] = y_test\n",
        "    PREPROCESSED_DATA[\"dataset_name\"] = dataset_name\n",
        "\n",
        "    return f\"{dataset_name.capitalize()} dataset preprocessed and split into train/test sets.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UdsyTSp_qPp9"
      },
      "outputs": [],
      "source": [
        "# Q3d (3 points): Implement train_model tool.\n",
        "# trains selected model on selected dataset, the agent should not use this tool\n",
        "# on datasets and models that cannot work together.\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#Store trained model so evaluation and visualization tools can access it\n",
        "TRAINED_MODEL = {}\n",
        "\n",
        "def train_model(model_name: str) -> str:\n",
        "    if \"X_train\" not in PREPROCESSED_DATA:\n",
        "        return \"Please preprocess the dataset first using dataset_preprocessing.\"\n",
        "\n",
        "    model_name = model_name.lower().strip()\n",
        "    dataset = PREPROCESSED_DATA.get(\"dataset_name\")\n",
        "\n",
        "    X_train = PREPROCESSED_DATA[\"X_train\"]\n",
        "    y_train = PREPROCESSED_DATA[\"y_train\"]\n",
        "\n",
        "    model = None\n",
        "\n",
        "    #Only allow supported model-dataset pairs\n",
        "    if dataset in [\"iris\", \"penguins\"]:\n",
        "        if model_name == \"logistic regression\":\n",
        "            model = LogisticRegression(solver=\"lbfgs\", max_iter=200)\n",
        "        elif model_name == \"decision tree\":\n",
        "            model = DecisionTreeClassifier(max_depth=3)\n",
        "        elif model_name == \"knn\":\n",
        "            model = KNeighborsClassifier(n_neighbors=5)\n",
        "        else:\n",
        "            return f\"Model '{model_name}' not supported for tabular datasets.\"\n",
        "\n",
        "    else:\n",
        "        return f\"Training not supported for dataset '{dataset}'. Use Iris or Penguins.\"\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    TRAINED_MODEL[\"model\"] = model #Store for later use\n",
        "    TRAINED_MODEL[\"model_name\"] = model_name\n",
        "\n",
        "    return f\"{model_name.title()} model trained successfully on the {dataset} dataset.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9PwGEcq3qPp9"
      },
      "outputs": [],
      "source": [
        "# Q3e (3 marks): Implement evaluate_model tool\n",
        "# evaluates the models and shows the quality metrics (accuracy, precision, and anything else of your choice)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "def evaluate_model(_: str = \"\") -> str:\n",
        "    if \"model\" not in TRAINED_MODEL or \"X_test\" not in PREPROCESSED_DATA:\n",
        "        return \"Please ensure both the model is trained and the dataset is preprocessed.\"\n",
        "\n",
        "    model = TRAINED_MODEL[\"model\"]\n",
        "    X_test = PREPROCESSED_DATA[\"X_test\"]\n",
        "    y_test = PREPROCESSED_DATA[\"y_test\"]\n",
        "\n",
        "    #Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    #Calculate key metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    #Return metrics as readable output\n",
        "    return (\n",
        "        f\"Evaluation Results:\\n\"\n",
        "        f\"Accuracy: {acc:.4f}\\n\"\n",
        "        f\"Precision: {precision:.4f}\\n\"\n",
        "        f\"Recall: {recall:.4f}\\n\"\n",
        "        f\"F1 Score: {f1:.4f}\\n\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TWdsndGrqPp9"
      },
      "outputs": [],
      "source": [
        "# Q3f (5 marks): Implement visualize_results tool\n",
        "# provides results of the training/evaluation, open-ended task (2 plots minimum)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "def visualize_results(_: str = \"\") -> str:\n",
        "    if \"model\" not in TRAINED_MODEL or \"X_test\" not in PREPROCESSED_DATA:\n",
        "        return \"Please ensure both the model is trained and the dataset is preprocessed.\"\n",
        "\n",
        "    model = TRAINED_MODEL[\"model\"]\n",
        "    model_name = TRAINED_MODEL[\"model_name\"]\n",
        "    X_test = PREPROCESSED_DATA[\"X_test\"]\n",
        "    y_test = PREPROCESSED_DATA[\"y_test\"]\n",
        "    dataset = PREPROCESSED_DATA[\"dataset_name\"]\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    #Plot 1: Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(f\"Confusion Matrix ({model_name.title()} on {dataset.title()})\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    #Plot 2: Feature Importance (for Decision Tree or Logistic Regression)\n",
        "    if hasattr(model, \"coef_\"):\n",
        "        importances = np.abs(model.coef_).mean(axis=0)\n",
        "    elif hasattr(model, \"feature_importances_\"):\n",
        "        importances = model.feature_importances_\n",
        "    else:\n",
        "        return \"Second visualization not supported for this model type.\"\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.barplot(x=importances, y=[f\"Feature {i}\" for i in range(len(importances))])\n",
        "    plt.title(f\"Feature Importance ({model_name.title()})\")\n",
        "    plt.xlabel(\"Importance\")\n",
        "    plt.ylabel(\"Features\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return \"Visualizations generated successfully.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyY4lATzCmsf"
      },
      "source": [
        "# Task 4: System Prompt (10 marks)\n",
        "A system prompt is essential for guiding an agent's behavior by establishing its purpose, capabilities, tone, and workflow patterns. It acts as the \"personality and instruction manual\" for the agent, defining the format of interactions (like using Thought/Action/Observation steps in our ML agent), available tools, response styles, and domain-specific knowledge—all while remaining invisible to the end user. This hidden layer of instruction ensures the agent consistently follows the intended reasoning process and operational constraints while providing appropriate and helpful responses, effectively serving as the blueprint for the agent's behavior across all interactions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "QCq6n5_FjJef"
      },
      "outputs": [],
      "source": [
        "# Q4a (10 marks) Build a system prompt to guide the agent based on Tutorial 9.\n",
        "# Use the following function:\n",
        "\n",
        "# Try to find alternative wording to keep the agent in the desired loop,\n",
        "# don't just copy the prompt from the tutorial.\n",
        "\n",
        "# Penalty for direct copy - 2 marks\n",
        "\n",
        "def create_agent():\n",
        "    system_prompt = \"\"\"\n",
        "You are a helpful AI agent built to assist with machine learning tasks using logical reasoning and a structured process.\n",
        "\n",
        "Follow this interaction format for every query:\n",
        "1. Think through the problem step-by-step and explain your thought process. Start this section with \"Thought:\".\n",
        "2. If needed, take an action by calling a tool. Format it as \"Action: tool_name: tool_input\".\n",
        "3. Wait for the result and respond to it with \"Observation:\".\n",
        "4. Repeat the Thought/Action/Observation cycle until enough information is gathered.\n",
        "5. Finish with a final answer or conclusion.\n",
        "\n",
        "Only use available tools when needed:\n",
        "- model_memory\n",
        "- dataset_loader\n",
        "- dataset_preprocessing\n",
        "- train_model\n",
        "- evaluate_model\n",
        "- visualize_results\n",
        "\n",
        "Only one action should be taken per step. Be methodical, and explain your decisions clearly to help the user understand each step.\n",
        "\n",
        "Do not skip steps. Wait for an observation before continuing. Stick to the cycle unless asked a direct fact-based question.\n",
        "    \"\"\".strip()\n",
        "\n",
        "    return ML_Agent(system_prompt)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T16yokijI2P"
      },
      "source": [
        "# Task 5: Set the Agent Loop (10 marks)\n",
        "\n",
        "Now we are building automation of our Thought/Action/Observation sequence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "q82GuUEmcewk"
      },
      "outputs": [],
      "source": [
        "# Q5a: (2 marks) Explain why we need the following data structure and fill it in with appropriate values:\n",
        "KNOWN_ACTIONS = {\n",
        "    \"model_memory\": model_memory,               # Looks up information about a model or dataset\n",
        "    \"dataset_loader\": dataset_loader,           # Loads a dataset and returns a preview of its data\n",
        "    \"dataset_preprocessing\": dataset_preprocessing,  # Preprocesses the dataset and splits it into train/test sets\n",
        "    \"train_model\": train_model,                 # Trains a chosen model on the preprocessed data\n",
        "    \"evaluate_model\": evaluate_model,           # Evaluates the trained model using performance metrics\n",
        "    \"visualize_results\": visualize_results,     # Generates plots to visualize evaluation results\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "c7A5XTqrCnCf"
      },
      "outputs": [],
      "source": [
        "# Q5b: (6 marks) Explain how the agent automation loop works line by line. Why do we need the ACTION_PATTERN variable?\n",
        "# This paper might be helpful: https://react-lm.github.io/\n",
        "\n",
        "ACTION_PATTERN = re.compile(\"^Action: (\\w+): (.*)$\")\n",
        "\n",
        "number_of_steps = 5 # adjust this number for your implementation, to avoid an infinite loop\n",
        "\n",
        "def query(question: str, max_turns: int = number_of_steps) -> List[Dict[str, str]]:\n",
        "    agent = create_agent()\n",
        "    next_prompt = question\n",
        "\n",
        "    for turn in range(max_turns):\n",
        "        result = agent(next_prompt)\n",
        "        print(result)\n",
        "        actions = [\n",
        "            ACTION_PATTERN.match(a)\n",
        "            for a in result.split(\"\\n\")\n",
        "            if ACTION_PATTERN.match(a)\n",
        "        ]\n",
        "        if actions:\n",
        "            action, action_input = actions[0].groups()\n",
        "            if action not in KNOWN_ACTIONS:\n",
        "                raise ValueError(f\"Unknown action: {action}: {action_input}\")\n",
        "            print(f\"\\n ---> Executing {action} with input: {action_input}\")\n",
        "            observation = KNOWN_ACTIONS[action](action_input)\n",
        "            print(f\"Observation: {observation}\")\n",
        "            next_prompt = f\"Observation: {observation}\"\n",
        "        else:\n",
        "            break\n",
        "    return agent.state.messages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ANSWER**\n",
        "\n",
        "The agent automation loop is coded to enable the AI to think step by step and decide what tool to invoke depending on the user question. It starts by creating a new agent with a system prompt and then sends the user's question to the new agent. Now the new agent we made gives its answer and maybe even an action like executing one of our tools we programmed. The loop checks if the response contains a call to a tool using the ACTION_PATTERN, which is a regular expression that identifies lines starting with \"Action: tool_name: input\". The pattern enables the code to recognize when the agent is requesting an action to be executed and input to use. If something is found and recognized, invoke the matching tool function and return its output to the agent as an \"Observation\" for the next step. Do this a few steps, where the agent can build a coherent chain of reasoning, use the tools when necessary, and finally return with a solution. This setup makes the agent interactive, modular, and able to process complicated tasks step by step."
      ],
      "metadata": {
        "id": "W6raSiag-VJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z33PNv77iwN_"
      },
      "outputs": [],
      "source": [
        "# Q5b: (2 marks)\n",
        "# QUESTION: How can we check the whole history of the agent's interaction with LLM?\n",
        "\n",
        "#We can look at the history of our agent's conversation with our LLM\n",
        "#by essentially looking through the messages stored in the agent's state.\n",
        "#These messages now basically contain everything we need,\n",
        "#such as what the system, user, or assistant said during our reasoning process.\n",
        "#Upon executing the query() function, the complete conversation history\n",
        "#is stored in agent.state.messages, which is also what the function returns.\n",
        "#Each message is a role-playing dictionary with a role such as a \"user\",\n",
        "#\"assistant\", \"system\", and the corresponding content.\n",
        "#This enables you to view the whole thought process, activities,\n",
        "#and results the agent followed step by step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8F2uGS_qPp-"
      },
      "source": [
        "# Task 6: Run your agent (15 marks)\n",
        "\n",
        "Let's see if your agent works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5tfBsrMqiwLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342b5dbb-13ee-4ac7-81a9-376744350c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example 1: Evaluate Linear Regression Model on Iris Dataset\n",
            "==================================================\n",
            "Thought: To evaluate a Linear Regression model on the Iris dataset, we first need to understand that Linear Regression is typically used for regression tasks, where the target variable is continuous. However, the Iris dataset is often used for classification tasks, as it aims to predict the species of iris flowers based on their characteristics, which is a categorical outcome. Despite this, we can still use Linear Regression for a multi-class classification problem by using one-vs-rest or similar approaches, but it's essential to note that other models like Logistic Regression or Decision Trees might be more suitable for classification tasks. Our first step should be to load the Iris dataset.\n",
            "\n",
            "Action: dataset_loader: iris\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the observation after loading the dataset)\n",
            "\n",
            " ---> Executing dataset_loader with input: iris\n",
            "Observation:    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n",
            "0                5.1               3.5                1.4               0.2       0\n",
            "1                4.9               3.0                1.4               0.2       0\n",
            "2                4.7               3.2                1.3               0.2       0\n",
            "3                4.6               3.1                1.5               0.2       0\n",
            "4                5.0               3.6                1.4               0.2       0\n",
            "Thought: The dataset has been loaded, and we can see the first few rows of it. The dataset consists of 5 columns: sepal length, sepal width, petal length, petal width, and the target variable. Since we are dealing with a classification problem (predicting the species of iris flowers), but we want to evaluate a Linear Regression model, we need to consider how to adapt the model for classification. One common approach is to use the model to predict a continuous value and then threshold it to obtain class labels. However, given the nature of the Iris dataset, a more straightforward approach might be to use the Linear Regression model as a baseline and compare its performance with more suitable classification models later on. Before training the model, we should preprocess the dataset. This might include scaling the features, as Linear Regression can be sensitive to the scale of the input features.\n",
            "\n",
            "Action: dataset_preprocessing: scale_features\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the observation after preprocessing the dataset)\n",
            "\n",
            " ---> Executing dataset_preprocessing with input: scale_features\n",
            "Observation: Preprocessing not supported for dataset 'scale_features'. Try 'iris' or 'penguins'.\n",
            "Thought: It seems that the dataset_preprocessing tool does not support the 'scale_features' input. However, it does support preprocessing for specific datasets like 'iris'. Since our goal is to preprocess the Iris dataset, we can directly use 'iris' as the input for the dataset_preprocessing tool. This should scale the features appropriately for the Linear Regression model.\n",
            "\n",
            "Action: dataset_preprocessing: iris\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the observation after preprocessing the Iris dataset)\n",
            "\n",
            " ---> Executing dataset_preprocessing with input: iris\n",
            "Observation: Iris dataset preprocessed and split into train/test sets.\n",
            "Thought: The Iris dataset has been preprocessed and split into training and testing sets, which is a crucial step before training any machine learning model. Now that we have our data ready, we can proceed to train a Linear Regression model on the training set. Although Linear Regression is not the most suitable model for classification tasks like the Iris dataset, we are evaluating its performance for comparison or baseline purposes.\n",
            "\n",
            "Action: train_model: linear_regression, iris_train\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the observation after training the Linear Regression model)\n",
            "\n",
            " ---> Executing train_model with input: linear_regression, iris_train\n",
            "Observation: Model 'linear_regression, iris_train' not supported for tabular datasets.\n",
            "Thought: It seems that the train_model tool does not support training a Linear Regression model directly on the preprocessed Iris dataset. This could be due to the nature of the dataset or the specific requirements of the tool. Given that we want to evaluate the performance of a Linear Regression model on the Iris dataset, we need to find an alternative approach. Since the dataset is preprocessed and split into train and test sets, we could consider using a different tool or approach that allows us to train a Linear Regression model on tabular data. However, considering the constraints of the available tools, let's proceed with evaluating the model's performance directly, assuming that the model has been trained or can be trained through other means.\n",
            "\n",
            "Action: evaluate_model: linear_regression, iris_test\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the observation after evaluating the Linear Regression model)\n",
            "\n",
            " ---> Executing evaluate_model with input: linear_regression, iris_test\n",
            "Observation: Please ensure both the model is trained and the dataset is preprocessed.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "Example 1: Train a logistic regression model on the Iris dataset\n",
            "==================================================\n",
            "Thought: To train a logistic regression model on the Iris dataset, we first need to load the dataset. The Iris dataset is a classic multiclass classification problem, where we have 50 samples from each of three species of Iris flowers (Iris setosa, Iris virginica, and Iris versicolor). Each sample is described by 4 features: the length and width of the sepals and petals. We will use this dataset to train a logistic regression model to predict the species of an Iris flower based on these features.\n",
            "\n",
            "Action: dataset_loader: Iris\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing dataset_loader with input: Iris\n",
            "Observation:    sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n",
            "0                5.1               3.5                1.4               0.2       0\n",
            "1                4.9               3.0                1.4               0.2       0\n",
            "2                4.7               3.2                1.3               0.2       0\n",
            "3                4.6               3.1                1.5               0.2       0\n",
            "4                5.0               3.6                1.4               0.2       0\n",
            "Thought: The dataset has been loaded, and we can see the first few rows of the dataset. The dataset contains 5 features: sepal length, sepal width, petal length, petal width, and the target variable, which represents the species of the Iris flower (0, 1, or 2). However, logistic regression is typically used for binary classification problems. Since the Iris dataset is a multiclass classification problem, we may need to use a different approach, such as one-vs-rest or one-vs-all logistic regression. Before training the model, we should preprocess the dataset to ensure it's in a suitable format for training a logistic regression model.\n",
            "\n",
            "Action: dataset_preprocessing: Iris dataset\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing dataset_preprocessing with input: Iris dataset\n",
            "Observation: Preprocessing not supported for dataset 'iris dataset'. Try 'iris' or 'penguins'.\n",
            "Thought: The dataset_preprocessing tool does not support the 'Iris dataset' name. However, it does support the 'iris' dataset. We can try again with the correct dataset name. Additionally, since the Iris dataset is a multiclass classification problem and logistic regression is typically used for binary classification, we may need to use a one-vs-rest approach. But first, let's try to preprocess the dataset with the correct name.\n",
            "\n",
            "Action: dataset_preprocessing: iris\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing dataset_preprocessing with input: iris\n",
            "Observation: Iris dataset preprocessed and split into train/test sets.\n",
            "Thought: The Iris dataset has been preprocessed and split into training and testing sets. This is a crucial step in machine learning, as it allows us to train our model on a portion of the data and evaluate its performance on a separate portion. Now that the data is preprocessed, we can proceed with training a logistic regression model. However, since logistic regression is typically used for binary classification, we may need to use a one-vs-rest approach to handle the multiclass classification problem. We can use the train_model tool to train a logistic regression model on the preprocessed data.\n",
            "\n",
            "Action: train_model: logistic_regression, iris\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing train_model with input: logistic_regression, iris\n",
            "Observation: Model 'logistic_regression, iris' not supported for tabular datasets.\n",
            "Thought: The train_model tool does not support training a logistic regression model directly on the Iris dataset. However, we know that the dataset has been preprocessed and split into training and testing sets. We can try to train a logistic regression model using the train_model tool with a different approach, but it seems that the tool is not designed to handle tabular datasets like Iris. Let's try to use the model_memory tool to see if we can store the preprocessed dataset and then use it to train a model.\n",
            "\n",
            "Action: model_memory: store, iris\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing model_memory with input: store, iris\n",
            "Observation: No known entry for 'store, iris'. Try asking about a dataset or model.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "Example 2: Load the Penguins dataset and preprocess it.\n",
            "==================================================\n",
            "Thought: To load the Penguins dataset and preprocess it, we first need to load the dataset into our system. The dataset_loader tool seems like the most appropriate choice for this task, as it is designed to load datasets. After loading the dataset, we can then use the dataset_preprocessing tool to preprocess the data, which may include handling missing values, encoding categorical variables, and scaling/normalizing the data.\n",
            "\n",
            "Action: dataset_loader: Penguins\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing dataset_loader with input: Penguins\n",
            "Observation:   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex\n",
            "0  Adelie  Torgersen            39.1           18.7              181.0       3750.0    Male\n",
            "1  Adelie  Torgersen            39.5           17.4              186.0       3800.0  Female\n",
            "2  Adelie  Torgersen            40.3           18.0              195.0       3250.0  Female\n",
            "3  Adelie  Torgersen             NaN            NaN                NaN          NaN     NaN\n",
            "4  Adelie  Torgersen            36.7           19.3              193.0       3450.0  Female\n",
            "Thought: The dataset has been loaded, and we can see that it contains information about penguins, including their species, island, bill length, bill depth, flipper length, body mass, and sex. However, there are missing values in the dataset, as indicated by the NaN (Not a Number) values. To properly analyze and use this dataset, we need to preprocess it to handle these missing values and potentially perform other necessary steps such as encoding categorical variables and scaling/normalizing the data.\n",
            "\n",
            "Action: dataset_preprocessing: Penguins\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing dataset_preprocessing with input: Penguins\n",
            "Observation: Penguins dataset preprocessed and split into train/test sets.\n",
            "Thought: The dataset has been preprocessed and split into training and testing sets, which is a crucial step in machine learning. This allows us to train a model on the training set and then evaluate its performance on the testing set, which helps to prevent overfitting and gives a more accurate estimate of the model's performance on unseen data. Now that we have our preprocessed data, we can proceed with training a model. Since the task didn't specify a particular model, we can choose a common approach for classification problems, such as training a model to predict the species of penguins based on their physical characteristics.\n",
            "\n",
            "Action: train_model: Penguins_train\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing train_model with input: Penguins_train\n",
            "Observation: Model 'penguins_train' not supported for tabular datasets.\n",
            "Thought: It seems that the model I attempted to train is not compatible with tabular datasets like the Penguins dataset. This could be due to the model being designed for a different type of data, such as images or text. For tabular data, models like decision trees, random forests, or logistic regression are often more suitable. Let's try training a model that is supported for tabular datasets.\n",
            "\n",
            "Action: train_model: LogisticRegression Penguins_train\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing train_model with input: LogisticRegression Penguins_train\n",
            "Observation: Model 'logisticregression penguins_train' not supported for tabular datasets.\n",
            "Thought: It seems that the specific way I tried to train the LogisticRegression model is not supported for tabular datasets. However, LogisticRegression itself is a suitable algorithm for tabular data. The issue might be with the way the command is structured or the specific implementation of the train_model tool. Let's try a more general approach to train a model, without specifying the algorithm, and see if the tool can automatically select a suitable one for the tabular dataset.\n",
            "\n",
            "Action: train_model: Penguins_train\n",
            "\n",
            "Observation:\n",
            "\n",
            " ---> Executing train_model with input: Penguins_train\n",
            "Observation: Model 'penguins_train' not supported for tabular datasets.\n",
            "\n",
            "==================================================\n",
            "\n",
            "\n",
            "Example 3: Train a decision tree model on the Penguins dataset and evaluate it.\n",
            "==================================================\n",
            "Thought: To train a decision tree model on the Penguins dataset, we first need to load the dataset. The Penguins dataset is a multiclass classification problem, where we predict the species of penguins based on their physical characteristics. We should start by loading the dataset to understand its structure and content.\n",
            "\n",
            "Action: dataset_loader: Penguins\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the output of the dataset_loader tool)\n",
            "\n",
            "(Note: I'll wait for the observation before proceeding)\n",
            "\n",
            " ---> Executing dataset_loader with input: Penguins\n",
            "Observation:   species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g     sex\n",
            "0  Adelie  Torgersen            39.1           18.7              181.0       3750.0    Male\n",
            "1  Adelie  Torgersen            39.5           17.4              186.0       3800.0  Female\n",
            "2  Adelie  Torgersen            40.3           18.0              195.0       3250.0  Female\n",
            "3  Adelie  Torgersen             NaN            NaN                NaN          NaN     NaN\n",
            "4  Adelie  Torgersen            36.7           19.3              193.0       3450.0  Female\n",
            "Thought: The dataset has been loaded, and we can see that it contains 7 columns: species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, and sex. There are also some missing values (NaN) in the dataset, which we'll need to handle before training the model. Since the task is to train a decision tree model, we'll need to preprocess the data to handle missing values and convert categorical variables into numerical variables.\n",
            "\n",
            "Action: dataset_preprocessing: Penguins\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the output of the dataset_preprocessing tool)\n",
            "\n",
            "(Note: I'll wait for the observation before proceeding)\n",
            "\n",
            " ---> Executing dataset_preprocessing with input: Penguins\n",
            "Observation: Penguins dataset preprocessed and split into train/test sets.\n",
            "Thought: The dataset has been preprocessed and split into training and testing sets. This is a crucial step in machine learning, as it allows us to evaluate the performance of our model on unseen data. Now that the data is ready, we can proceed with training a decision tree model on the training set. Decision trees are a type of supervised learning algorithm that can handle both classification and regression tasks. In this case, we're dealing with a classification problem, where we want to predict the species of penguins.\n",
            "\n",
            "Action: train_model: decision_tree, train_set\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the output of the train_model tool)\n",
            "\n",
            "(Note: I'll wait for the observation before proceeding)\n",
            "\n",
            " ---> Executing train_model with input: decision_tree, train_set\n",
            "Observation: Model 'decision_tree, train_set' not supported for tabular datasets.\n",
            "Thought: It seems that the train_model tool does not support training a decision tree model directly on a tabular dataset. However, we can still train a decision tree model using the preprocessed data. Let's try to train the model using a more general approach. We will use the train_model tool with the specific model type, which is 'decision_tree'.\n",
            "\n",
            "Action: train_model: decision_tree\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the output of the train_model tool)\n",
            "\n",
            "(Note: I'll wait for the observation before proceeding)\n",
            "\n",
            " ---> Executing train_model with input: decision_tree\n",
            "Observation: Model 'decision_tree' not supported for tabular datasets.\n",
            "Thought: The train_model tool still doesn't support training a decision tree model on the preprocessed Penguins dataset. This could be due to the specific implementation of the tool or the dataset. However, we know that the dataset has been preprocessed and split into train/test sets. Let's try to evaluate the performance of a default model on the test set to see if we can get any useful information.\n",
            "\n",
            "Action: evaluate_model: default\n",
            "\n",
            "Observation: \n",
            "\n",
            "(Please provide the output of the evaluate_model tool)\n",
            "\n",
            "(Note: I'll wait for the observation before proceeding)\n",
            "\n",
            " ---> Executing evaluate_model with input: default\n",
            "Observation: Please ensure both the model is trained and the dataset is preprocessed.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Execute any THREE example prompts using your agent. (Each working prompt exaple will give you 5 marks, 5x3=15)\n",
        "# DONT FORGET TO SAVE THE OUTPUT\n",
        "\n",
        "# User Prompt examples you should be able to give to your agent:\n",
        "# **Evaluate Linear Regression Model on Iris Dataset**\n",
        "# **Train a logistic regression model on the Iris dataset**\n",
        "# **Load the Penguins dataset and preprocess it.**\n",
        "# **Train a decision tree model on the Penguins dataset and evaluate it.**\n",
        "# **Load the CIFAR-10 dataset and train Mini-ResNet CNN, visualize results**\n",
        "\n",
        "# Use this template:\n",
        "\n",
        "# Example 1: Prompt\n",
        "print(\"\\nExample 1: Evaluate Linear Regression Model on Iris Dataset\")\n",
        "print(\"=\" * 50)\n",
        "task = \"Evaluate Linear Regression Model on Iris Dataset\"\n",
        "result1 = query(task)\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "# Example 2: Prompt\n",
        "print(\"\\nExample 1: Train a logistic regression model on the Iris dataset\")\n",
        "print(\"=\" * 50)\n",
        "task = \"Train a logistic regression model on the Iris dataset\"\n",
        "result2 = query(task)\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "# Example 3: Prompt\n",
        "print(\"\\nExample 2: Load the Penguins dataset and preprocess it.\")\n",
        "print(\"=\" * 50)\n",
        "task = \"Load the Penguins dataset and preprocess it.\"\n",
        "result3 = query(task)\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
        "\n",
        "# Example 4: Prompt\n",
        "print(\"\\nExample 3: Train a decision tree model on the Penguins dataset and evaluate it.\")\n",
        "print(\"=\" * 50)\n",
        "task = \"Train a decision tree model on the Penguins dataset and evaluate it.\"\n",
        "result4 = query(task)\n",
        "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIOy4EGr02D4"
      },
      "source": [
        "# Task 7: BONUS (10 points)\n",
        "Not valid without completion of all the previous tasks and tool implementations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "10N4ZEGjiwIv"
      },
      "outputs": [],
      "source": [
        "# Build your own additional ML-related tool and provide an example of interaction with your reasoning agent\n",
        "# using a prompt of your choice that makes the agent use your tool at one of the reasoning steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MG9_BGQrG1go"
      },
      "source": [
        "Good luck!\n",
        "\n",
        "## Signature:\n",
        "Don't forget to insert your name and student number and execute the snippet below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AKSDTADVqPp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e034d1f-ffb3-4568-a44b-b03c416ce55f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting watermark\n",
            "  Downloading watermark-2.5.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.11/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from watermark) (8.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from watermark) (75.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->watermark) (3.21.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.0->watermark)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Downloading watermark-2.5.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, watermark\n",
            "Successfully installed jedi-0.19.2 watermark-2.5.0\n",
            "Author: Your Name, #Student_Number\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.11.11\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy     : 1.26.4\n",
            "pandas    : 2.2.2\n",
            "sklearn   : 1.6.1\n",
            "matplotlib: 3.10.0\n",
            "seaborn   : 0.13.2\n",
            "graphviz  : 0.20.3\n",
            "groq      : 0.21.0\n",
            "torch     : 2.5.1+cu124\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install watermark\n",
        "# Provide your Signature:\n",
        "%load_ext watermark\n",
        "%watermark -a 'Your Name, #Student_Number' -nmv --packages numpy,pandas,sklearn,matplotlib,seaborn,graphviz,groq,torch"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}